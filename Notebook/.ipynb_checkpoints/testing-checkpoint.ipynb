{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated ðŸ˜Ÿ</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wro...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy ðŸ˜ </td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                             i didnt feel humiliated ðŸ˜Ÿ   sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2      im grabbing a minute to post i feel greedy wro...    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                i am feeling grouchy ðŸ˜      anger\n",
       "...                                                  ...      ...\n",
       "19995  i just keep feeling like someone is being unki...    anger\n",
       "19996  im feeling a little cranky negative after this...    anger\n",
       "19997  i feel that i am useful to my people and that ...      joy\n",
       "19998  im feeling more comfortable with derby i feel ...      joy\n",
       "19999  i feel all weird when i have to meet w people ...     fear\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(os.getcwd(),\"../static/dataset/emoji_dataset.csv\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Text','Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validate, test = np.split(data.sample(frac=1, random_state=42), [int(.8*len(data)), int(0.9*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "# def preprocess(x):\n",
    "#     x = ' '.join([item for item in str(x).split() if item not in stopwords.words('english')])\n",
    "#     x = ' '.join(x.lower() for x in x.split())\n",
    "#     x = emoji.demojize(x)\n",
    "#     x = x.replace('[^\\w\\s]',' ')\n",
    "#     x = ' '.join([Word(word).lemmatize() for word in x.split()])\n",
    "#     x = ' '.join(de_repeat(x) for x in x.split())\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>noticed several month ago start feeling resent...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>love lot different kind sport love hanging fri...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>feel even killed agonized extent loudly_crying...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>feel numb way wound really start hurt slightly...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>feel happy inspired little si love reading wri...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7382</th>\n",
       "      <td>pay month month feel shame every time grill ho...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13492</th>\n",
       "      <td>feeling determined going get face_with_tears_o...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10394</th>\n",
       "      <td>remember feeling bit confused really questione...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16865</th>\n",
       "      <td>feel helpless look world fearful_face</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>believe happy healthy relationship likely feel...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "10650  noticed several month ago start feeling resent...    anger\n",
       "2041   love lot different kind sport love hanging fri...      joy\n",
       "8668   feel even killed agonized extent loudly_crying...  sadness\n",
       "1114   feel numb way wound really start hurt slightly...  sadness\n",
       "13902  feel happy inspired little si love reading wri...      joy\n",
       "...                                                  ...      ...\n",
       "7382   pay month month feel shame every time grill ho...     love\n",
       "13492  feeling determined going get face_with_tears_o...      joy\n",
       "10394  remember feeling bit confused really questione...     fear\n",
       "16865              feel helpless look world fearful_face     fear\n",
       "5047   believe happy healthy relationship likely feel...      joy\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "train['Text'] = train['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "train['Text'] = train['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train['Text'] = train['Text'].apply(lambda x: emoji.demojize(x))\n",
    "train['Text'] = train['Text'].str.replace('[^\\w\\s]',' ')\n",
    "train['Text'] = train['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train['Text'] = train['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>go detail long night woke bus feeling like cou...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19010</th>\n",
       "      <td>im feeling tortured write today grimacing_face</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>still feel like tragic waste pleading_face</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>feel humiliated body husband make advance towa...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>feel horribly insecure fearful_face</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>feel helpless make real difference pensive_face</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>feel impatient much thanks nic know calm face_...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>feel outraged life easy blessed angry_face_wit...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>feel like witnessing birth really amazing dm f...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>flipped guy feel terrible today flipped guy fe...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "1262   go detail long night woke bus feeling like cou...      joy\n",
       "19010     im feeling tortured write today grimacing_face     fear\n",
       "7212          still feel like tragic waste pleading_face  sadness\n",
       "975    feel humiliated body husband make advance towa...  sadness\n",
       "2566                 feel horribly insecure fearful_face     fear\n",
       "...                                                  ...      ...\n",
       "10900    feel helpless make real difference pensive_face  sadness\n",
       "7758   feel impatient much thanks nic know calm face_...    anger\n",
       "4837   feel outraged life easy blessed angry_face_wit...    anger\n",
       "6548   feel like witnessing birth really amazing dm f...      joy\n",
       "4481   flipped guy feel terrible today flipped guy fe...  sadness\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate['Text'] = validate['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "validate['Text'] = validate['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "validate['Text'] = validate['Text'].apply(lambda x: emoji.demojize(x))\n",
    "validate['Text'] = validate['Text'].str.replace('[^\\w\\s]',' ')\n",
    "validate['Text'] = validate['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "validate['Text'] = validate['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "validate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>didnt want lazy feel groggy kept drinking red ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10837</th>\n",
       "      <td>thought good idea gave time recover feeling ne...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>feel like didnt really care alexis irritated e...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>feel stress free heading holiday rolling_on_th...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>keep feeling sometimes one fake till make cryi...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>want savor feeling ecstatic anticipation abide...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>im feeling puppy dog rainbow im exhausted yes ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>feel delicate bouquet</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>starting feel little stressed broken_heart</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>feel stressed tired worn shape neglected worri...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "3716   didnt want lazy feel groggy kept drinking red ...  sadness\n",
       "10837  thought good idea gave time recover feeling ne...     fear\n",
       "6140   feel like didnt really care alexis irritated e...    anger\n",
       "9956   feel stress free heading holiday rolling_on_th...      joy\n",
       "1549   keep feeling sometimes one fake till make cryi...  sadness\n",
       "...                                                  ...      ...\n",
       "11284  want savor feeling ecstatic anticipation abide...      joy\n",
       "11964  im feeling puppy dog rainbow im exhausted yes ...  sadness\n",
       "5390                               feel delicate bouquet     love\n",
       "860           starting feel little stressed broken_heart  sadness\n",
       "15795  feel stressed tired worn shape neglected worri...  sadness\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Text'] = test['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "test['Text'] = test['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test['Text'] = test['Text'].apply(lambda x: emoji.demojize(x))\n",
    "test['Text'] = test['Text'].str.replace('[^\\w\\s]',' ')\n",
    "test['Text'] = test['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "test['Text'] = test['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13470 unique words.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_texts = train['Text']\n",
    "tokenizer = Tokenizer(15212,lower=True,oov_token='UNK')\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "print('Found %d unique words.' % len(tokenizer.word_index))\n",
    "\n",
    "# texts_to_sequences: Transforms each text in texts to a sequence of integers. \n",
    "# It basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
    "\n",
    "train_texts_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "# pad_sequences: Ensure that all sequences in a list have the same length. \n",
    "train_texts_pad_sequences = pad_sequences(train_texts_sequences, maxlen=80, padding='post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "emotions = {'sadness': 0, 'joy': 1, 'surprise': 2, 'love': 3, 'anger': 4, 'fear': 5}\n",
    "\n",
    "# Step 1: Replace all emotion values with integers\n",
    "train['Emotion'] = train.Emotion.replace(emotions)\n",
    "train_emotion_integers = train['Emotion'].values\n",
    "\n",
    "# Step 2: Changing the integers to binary\n",
    "train_emotion_categorical = to_categorical(train_emotion_integers)\n",
    "train_emotion_categorical[:6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_texts = validate['Text']\n",
    "validate_emotion_integers = validate.Emotion.replace(emotions)\n",
    "validate_texts_sequences = tokenizer.texts_to_sequences(validate_texts)\n",
    "validate_texts_pad_sequences = pad_sequences(validate_texts_sequences, maxlen=80, padding='post')\n",
    "validate_emotion_categorical = to_categorical(validate_emotion_integers.values)\n",
    "validate_emotion_categorical[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "  tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "  tpu_strategy = tf.distribute.get_strategy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 80, 64)            973568    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 80, 64)            0         \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 80, 160)          92800     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 320)              410880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 1926      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,479,174\n",
      "Trainable params: 1,479,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,Dense,Embedding,Dropout\n",
    "\n",
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "with tpu_strategy.scope():\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(15212,64,input_length=80))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Bidirectional(LSTM(80,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(160)))\n",
    "    model.add(Dense(len(emotions),activation='softmax'))\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 376s 733ms/step - loss: 0.6248 - accuracy: 0.7656 - val_loss: 0.1624 - val_accuracy: 0.9510\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 281s 562ms/step - loss: 0.1307 - accuracy: 0.9582 - val_loss: 0.0707 - val_accuracy: 0.9765\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 263s 525ms/step - loss: 0.0684 - accuracy: 0.9800 - val_loss: 0.0499 - val_accuracy: 0.9860\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 262s 525ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.0516 - val_accuracy: 0.9835\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 260s 521ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.0416 - val_accuracy: 0.9855\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 261s 522ms/step - loss: 0.0249 - accuracy: 0.9929 - val_loss: 0.0492 - val_accuracy: 0.9855\n",
      "Epoch 7/10\n",
      "334/500 [===================>..........] - ETA: 1:28 - loss: 0.0154 - accuracy: 0.9954"
     ]
    }
   ],
   "source": [
    "hist=model.fit(train_texts_pad_sequences, train_emotion_categorical, epochs=10, validation_data = (validate_texts_pad_sequences, validate_emotion_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test['Text']\n",
    "test_emotion_integers = test.Emotion.replace(emotions)\n",
    "test_texts_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_texts_pad_sequences = pad_sequences(test_texts_sequences, maxlen=80, padding='post')\n",
    "test_emotion_categorical = to_categorical(test_emotion_integers.values)\n",
    "test_emotion_categorical[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.evaluate(test_texts_pad_sequences, test_emotion_categorical)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential, model_from_json\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# import numpy\n",
    "# import os\n",
    "# model_json = model.to_json()\n",
    "# with open(\"../static/model/model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"../static/model/model.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # dump information to that file\n",
    "# pickle.dump(tokenizer, open('../static/model/tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
