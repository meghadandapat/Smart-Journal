{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling groggy and horrid</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i could feel the muscles in my arches ankles a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like but im not very fond of that word 💙</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have to move stop staring at the other ladie...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have this kind of life so my girlfriend woul...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>im feeling ive resolved to live a life of love...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>i used feel frustrated all the time</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>im starting to feel more sociable again i actu...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>i am feeling devastated the inner voice within...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>i feel and oh how my heart broke</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                           im feeling groggy and horrid  sadness\n",
       "1      i could feel the muscles in my arches ankles a...      joy\n",
       "2       i feel like but im not very fond of that word 💙      love\n",
       "3      i have to move stop staring at the other ladie...      joy\n",
       "4      i have this kind of life so my girlfriend woul...  sadness\n",
       "...                                                  ...      ...\n",
       "19995  im feeling ive resolved to live a life of love...      joy\n",
       "19996                i used feel frustrated all the time    anger\n",
       "19997  im starting to feel more sociable again i actu...      joy\n",
       "19998  i am feeling devastated the inner voice within...  sadness\n",
       "19999                   i feel and oh how my heart broke  sadness\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(os.getcwd(),\"../static/dataset/emoji_dataset.csv\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Text','Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validate, test = np.split(data.sample(frac=1, random_state=42), [int(.8*len(data)), int(0.9*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>ive reading blog year feel like shes faithful ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>im feeling craving naughty sweet snack choose</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>im hoping theyll like new draft better time wo...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>crappy week still feeling agitated like day wa...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>easily feel quite pressured routine really not...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7382</th>\n",
       "      <td>feel bit funny actually</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13492</th>\n",
       "      <td>met great people feeling may unintentionally o...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10394</th>\n",
       "      <td>feel must remain faithful</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16865</th>\n",
       "      <td>havent felt like real good feeling welcomed op...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>feeling good run feel normal</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text   Emotion\n",
       "10650  ive reading blog year feel like shes faithful ...       joy\n",
       "2041       im feeling craving naughty sweet snack choose      love\n",
       "8668   im hoping theyll like new draft better time wo...   sadness\n",
       "1114   crappy week still feeling agitated like day wa...      fear\n",
       "13902  easily feel quite pressured routine really not...      fear\n",
       "...                                                  ...       ...\n",
       "7382                             feel bit funny actually  surprise\n",
       "13492  met great people feeling may unintentionally o...     anger\n",
       "10394                          feel must remain faithful       joy\n",
       "16865  havent felt like real good feeling welcomed op...       joy\n",
       "5047                        feeling good run feel normal       joy\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'] = train['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "train['Text'] = train['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train['Text'] = train['Text'].apply(lambda x: emoji.demojize(x))\n",
    "train['Text'] = train['Text'].str.replace('[^\\w\\s]',' ')\n",
    "train['Text'] = train['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train['Text'] = train['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>feel offended think justly</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19010</th>\n",
       "      <td>spent two week zombie mode two week feeling fe...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>love idea white blouse jumper feel jumper woul...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>couldnt help feel infuriated left building</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>think noticing prone feel jealous right helpin...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>angry feeling disillusioned</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>feel like someone need invest money could gorg...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>id let kill matter fact im feeling frightfully...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>feel though people find quite pleasant smiling...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>dont even think would ready fuck buddy there e...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "1262                          feel offended think justly    anger\n",
       "19010  spent two week zombie mode two week feeling fe...  sadness\n",
       "7212   love idea white blouse jumper feel jumper woul...  sadness\n",
       "975           couldnt help feel infuriated left building    anger\n",
       "2566   think noticing prone feel jealous right helpin...    anger\n",
       "...                                                  ...      ...\n",
       "10900                        angry feeling disillusioned  sadness\n",
       "7758   feel like someone need invest money could gorg...      joy\n",
       "4837   id let kill matter fact im feeling frightfully...      joy\n",
       "6548   feel though people find quite pleasant smiling...      joy\n",
       "4481   dont even think would ready fuck buddy there e...  sadness\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate['Text'] = validate['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "validate['Text'] = validate['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "validate['Text'] = validate['Text'].apply(lambda x: emoji.demojize(x))\n",
    "validate['Text'] = validate['Text'].str.replace('[^\\w\\s]',' ')\n",
    "validate['Text'] = validate['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "validate['Text'] = validate['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "validate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>think many may dislike still feel impressed ed...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10837</th>\n",
       "      <td>feel smart though</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>feel desperately fond</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>also able get appointment osteopath freaking a...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>feel taste dessert sweet suit many customer</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>id gotten past whole oh gawd im humiliated did...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>look see stare feel also know sympathetic glan...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>sound desperate pathetic feel frantic need anx...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>worried feeling supposed church rich dr</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>exercise feel energetic able perform task good...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text   Emotion\n",
       "3716   think many may dislike still feel impressed ed...  surprise\n",
       "10837                                  feel smart though       joy\n",
       "6140                               feel desperately fond      love\n",
       "9956   also able get appointment osteopath freaking a...      love\n",
       "1549         feel taste dessert sweet suit many customer      love\n",
       "...                                                  ...       ...\n",
       "11284  id gotten past whole oh gawd im humiliated did...   sadness\n",
       "11964  look see stare feel also know sympathetic glan...      love\n",
       "5390   sound desperate pathetic feel frantic need anx...      fear\n",
       "860              worried feeling supposed church rich dr       joy\n",
       "15795  exercise feel energetic able perform task good...       joy\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Text'] = test['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "test['Text'] = test['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test['Text'] = test['Text'].apply(lambda x: emoji.demojize(x))\n",
    "test['Text'] = test['Text'].str.replace('[^\\w\\s]',' ')\n",
    "test['Text'] = test['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "test['Text'] = test['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13470 unique words.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_texts = train['Text']\n",
    "tokenizer = Tokenizer(15212,lower=True,oov_token='UNK')\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "print('Found %d unique words.' % len(tokenizer.word_index))\n",
    "\n",
    "# texts_to_sequences: Transforms each text in texts to a sequence of integers. \n",
    "# It basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
    "\n",
    "train_texts_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "# pad_sequences: Ensure that all sequences in a list have the same length. \n",
    "train_texts_pad_sequences = pad_sequences(train_texts_sequences, maxlen=80, padding='post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "emotions = {'sadness': 0, 'joy': 1, 'surprise': 2, 'love': 3, 'anger': 4, 'fear': 5}\n",
    "\n",
    "# Step 1: Replace all emotion values with integers\n",
    "train['Emotion'] = train.Emotion.replace(emotions)\n",
    "train_emotion_integers = train['Emotion'].values\n",
    "\n",
    "# Step 2: Changing the integers to binary\n",
    "train_emotion_categorical = to_categorical(train_emotion_integers)\n",
    "train_emotion_categorical[:6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_texts = validate['Text']\n",
    "validate_emotion_integers = validate.Emotion.replace(emotions)\n",
    "validate_texts_sequences = tokenizer.texts_to_sequences(validate_texts)\n",
    "validate_texts_pad_sequences = pad_sequences(validate_texts_sequences, maxlen=80, padding='post')\n",
    "validate_emotion_categorical = to_categorical(validate_emotion_integers.values)\n",
    "validate_emotion_categorical[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "  tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "  tpu_strategy = tf.distribute.get_strategy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 80, 64)            973568    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 80, 64)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 80, 160)          92800     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 320)              410880    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1926      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,479,174\n",
      "Trainable params: 1,479,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,Dense,Embedding,Dropout\n",
    "\n",
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "with tpu_strategy.scope():\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(15212,64,input_length=80))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Bidirectional(LSTM(80,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(160)))\n",
    "    model.add(Dense(len(emotions),activation='softmax'))\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 271s 511ms/step - loss: 1.0789 - accuracy: 0.5878 - val_loss: 0.5386 - val_accuracy: 0.8155\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 241s 483ms/step - loss: 0.4093 - accuracy: 0.8602 - val_loss: 0.2912 - val_accuracy: 0.9020\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 746s 1s/step - loss: 0.2145 - accuracy: 0.9281 - val_loss: 0.1958 - val_accuracy: 0.9255\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 242s 484ms/step - loss: 0.1484 - accuracy: 0.9485 - val_loss: 0.1740 - val_accuracy: 0.9260\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 230s 459ms/step - loss: 0.1135 - accuracy: 0.9581 - val_loss: 0.1723 - val_accuracy: 0.9380\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 206s 411ms/step - loss: 0.0975 - accuracy: 0.9639 - val_loss: 0.1725 - val_accuracy: 0.9315\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 204s 408ms/step - loss: 0.0804 - accuracy: 0.9707 - val_loss: 0.1597 - val_accuracy: 0.9290\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 200s 400ms/step - loss: 0.0763 - accuracy: 0.9716 - val_loss: 0.1713 - val_accuracy: 0.9330\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 200s 400ms/step - loss: 0.0632 - accuracy: 0.9768 - val_loss: 0.1651 - val_accuracy: 0.9365\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 203s 405ms/step - loss: 0.0581 - accuracy: 0.9777 - val_loss: 0.1568 - val_accuracy: 0.9325\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(train_texts_pad_sequences, train_emotion_categorical, epochs=10, validation_data = (validate_texts_pad_sequences, validate_emotion_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts = test['Text']\n",
    "test_emotion_integers = test.Emotion.replace(emotions)\n",
    "test_texts_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_texts_pad_sequences = pad_sequences(test_texts_sequences, maxlen=80, padding='post')\n",
    "test_emotion_categorical = to_categorical(test_emotion_integers.values)\n",
    "test_emotion_categorical[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 8s 130ms/step - loss: 0.1847 - accuracy: 0.9345\n",
      "[0.1847209930419922, 0.934499979019165]\n"
     ]
    }
   ],
   "source": [
    "x = model.evaluate(test_texts_pad_sequences, test_emotion_categorical)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../static/model/m2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(\"../static/model/m2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    df = pd.DataFrame({'Text':[text]})\n",
    "    df['Text'] = df['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "    df['Text'] = df['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    df['Text'] = df['Text'].apply(lambda x: emoji.demojize(x))\n",
    "    df['Text'] = df['Text'].str.replace('[^\\w\\s]',' ')\n",
    "    df['Text'] = df['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    df['Text'] = df['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "    df_texts = df['Text']\n",
    "    df_texts_sequences = tokenizer.texts_to_sequences(df_texts)\n",
    "    df_texts_pad_sequences = pad_sequences(df_texts_sequences, maxlen=80, padding='post')\n",
    "    return df_texts_pad_sequences\n",
    "\n",
    "\n",
    "def mood_result(sentence):\n",
    "    testing = preprocess_text(sentence)  \n",
    "    result = model.predict(testing)[0]\n",
    "    for key,val in emotions.items():\n",
    "        print(key + ': ' + str(round(result[val]*100,2)) + ' %')\n",
    "    val = np.argmax(result)\n",
    "    emotion = [key for key, value in emotions.items() if value == val]\n",
    "    return emotion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "sadness: 2.08 %\n",
      "joy: 1.34 %\n",
      "surprise: 1.48 %\n",
      "love: 0.9 %\n",
      "anger: 90.67 %\n",
      "fear: 3.53 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am happy 💔 because he is angry 🎁 \"\n",
    "mood_result(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "sadness: 99.96 %\n",
      "joy: 0.01 %\n",
      "surprise: 0.0 %\n",
      "love: 0.0 %\n",
      "anger: 0.01 %\n",
      "fear: 0.02 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"A wedding can be a highly emotional event.\"\n",
    "mood_result(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
