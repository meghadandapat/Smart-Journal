{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15760919",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d9529b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec61c0",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08c5bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\n",
    "    os.path.join(os.getcwd(),\"../static/dataset/train.txt\"),\n",
    "    sep=\";\",\n",
    "    names=[\"Text\",\"Emotion\"],\n",
    "    encoding='utf-8')\n",
    "\n",
    "validate=pd.read_csv(\n",
    "   os.path.join(os.getcwd(),\"../static/dataset/val.txt\"),\n",
    "    sep=\";\",\n",
    "    names=[\"Text\",\"Emotion\"],\n",
    "    encoding='utf-8')\n",
    "\n",
    "test=pd.read_csv( \n",
    "    os.path.join(os.getcwd(),\"../static/dataset/test.txt\"),\n",
    "    sep=\";\",\n",
    "    names=[\"Text\",\"Emotion\"],\n",
    "    encoding='utf-8')\n",
    "\n",
    "merged = pd.concat([train, validate, test], ignore_index=True)\n",
    "\n",
    "datasets = [train, validate, test]\n",
    "datasetnames = ['Train', 'Validate', 'Test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a511f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>i noticed several months ago that i d start fe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>i love lots of different kinds of sports and l...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>i feel even if he killed himself it was becaus...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>i feel numb the way a wound does before it rea...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>i feel very happy to have inspired is my littl...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "10650  i noticed several months ago that i d start fe...    anger\n",
       "2041   i love lots of different kinds of sports and l...      joy\n",
       "8668   i feel even if he killed himself it was becaus...  sadness\n",
       "1114   i feel numb the way a wound does before it rea...  sadness\n",
       "13902  i feel very happy to have inspired is my littl...      joy"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b02889",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1f22779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "train['Text'] = train['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "validate['Text'] = validate['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "503198ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>noticed several months ago start feeling resen...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>love lots different kinds sports love hanging ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>feel even killed agonized extent</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>feel numb way wound really starts hurt</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>feel happy inspired little sis love reading wr...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "10650  noticed several months ago start feeling resen...    anger\n",
       "2041   love lots different kinds sports love hanging ...      joy\n",
       "8668                    feel even killed agonized extent  sadness\n",
       "1114              feel numb way wound really starts hurt  sadness\n",
       "13902  feel happy inspired little sis love reading wr...      joy"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81517c86",
   "metadata": {},
   "source": [
    "Converting words to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5baaa032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>noticed several months ago start feeling resen...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>love lots different kinds sports love hanging ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>feel even killed agonized extent</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>feel numb way wound really starts hurt</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>feel happy inspired little sis love reading wr...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>im joking feeling either extremely friendly ha...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>feel like creative professional need unpressed...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19623</th>\n",
       "      <td>feel sure go beyond</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15518</th>\n",
       "      <td>feel honoured asked thanks href http doodlesan...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17254</th>\n",
       "      <td>im fighting sniffles developed last night wasn...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "10650  noticed several months ago start feeling resen...    anger\n",
       "2041   love lots different kinds sports love hanging ...      joy\n",
       "8668                    feel even killed agonized extent  sadness\n",
       "1114              feel numb way wound really starts hurt  sadness\n",
       "13902  feel happy inspired little sis love reading wr...      joy\n",
       "...                                                  ...      ...\n",
       "3697   im joking feeling either extremely friendly ha...      joy\n",
       "2013   feel like creative professional need unpressed...      joy\n",
       "19623                                feel sure go beyond      joy\n",
       "15518  feel honoured asked thanks href http doodlesan...      joy\n",
       "17254  im fighting sniffles developed last night wasn...      joy\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'] = train['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ba974",
   "metadata": {},
   "source": [
    "Removing Punctuation, Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d73d0fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>noticed several months ago start feeling resen...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>love lots different kinds sports love hanging ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>feel even killed agonized extent</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>feel numb way wound really starts hurt</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>feel happy inspired little sis love reading wr...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>im joking feeling either extremely friendly ha...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>feel like creative professional need unpressed...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19623</th>\n",
       "      <td>feel sure go beyond</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15518</th>\n",
       "      <td>feel honoured asked thanks href http doodlesan...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17254</th>\n",
       "      <td>im fighting sniffles developed last night wasn...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "10650  noticed several months ago start feeling resen...    anger\n",
       "2041   love lots different kinds sports love hanging ...      joy\n",
       "8668                    feel even killed agonized extent  sadness\n",
       "1114              feel numb way wound really starts hurt  sadness\n",
       "13902  feel happy inspired little sis love reading wr...      joy\n",
       "...                                                  ...      ...\n",
       "3697   im joking feeling either extremely friendly ha...      joy\n",
       "2013   feel like creative professional need unpressed...      joy\n",
       "19623                                feel sure go beyond      joy\n",
       "15518  feel honoured asked thanks href http doodlesan...      joy\n",
       "17254  im fighting sniffles developed last night wasn...      joy\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'] = train['Text'].str.replace('[^\\w\\s]',' ')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297d623e",
   "metadata": {},
   "source": [
    "Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe8a4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>noticed several month ago start feeling resent...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>love lot different kind sport love hanging fri...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>feel even killed agonized extent</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>feel numb way wound really start hurt</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>feel happy inspired little si love reading wri...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>im joking feeling either extremely friendly ha...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>feel like creative professional need unpressed...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19623</th>\n",
       "      <td>feel sure go beyond</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15518</th>\n",
       "      <td>feel honoured asked thanks href http doodlesan...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17254</th>\n",
       "      <td>im fighting sniffle developed last night wasnt...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "10650  noticed several month ago start feeling resent...    anger\n",
       "2041   love lot different kind sport love hanging fri...      joy\n",
       "8668                    feel even killed agonized extent  sadness\n",
       "1114               feel numb way wound really start hurt  sadness\n",
       "13902  feel happy inspired little si love reading wri...      joy\n",
       "...                                                  ...      ...\n",
       "3697   im joking feeling either extremely friendly ha...      joy\n",
       "2013   feel like creative professional need unpressed...      joy\n",
       "19623                                feel sure go beyond      joy\n",
       "15518  feel honoured asked thanks href http doodlesan...      joy\n",
       "17254  im fighting sniffle developed last night wasnt...      joy\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'] = train['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466d3be",
   "metadata": {},
   "source": [
    "Correcting Letter Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d6e75e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>noticed several month ago start feeling resent...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>love lot different kind sport love hanging fri...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>feel even killed agonized extent</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>feel numb way wound really start hurt</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>feel happy inspired little si love reading wri...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>im joking feeling either extremely friendly ha...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>feel like creative professional need unpressed...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19623</th>\n",
       "      <td>feel sure go beyond</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15518</th>\n",
       "      <td>feel honoured asked thanks href http doodlesan...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17254</th>\n",
       "      <td>im fighting sniffle developed last night wasnt...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "10650  noticed several month ago start feeling resent...    anger\n",
       "2041   love lot different kind sport love hanging fri...      joy\n",
       "8668                    feel even killed agonized extent  sadness\n",
       "1114               feel numb way wound really start hurt  sadness\n",
       "13902  feel happy inspired little si love reading wri...      joy\n",
       "...                                                  ...      ...\n",
       "3697   im joking feeling either extremely friendly ha...      joy\n",
       "2013   feel like creative professional need unpressed...      joy\n",
       "19623                                feel sure go beyond      joy\n",
       "15518  feel honoured asked thanks href http doodlesan...      joy\n",
       "17254  im fighting sniffle developed last night wasnt...      joy\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "train['Text'] = train['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564dccc",
   "metadata": {},
   "source": [
    "## 1. Deep learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6202e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11720 unique words.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_texts = train['Text']\n",
    "\n",
    "tokenizer = Tokenizer(15212,lower=True,oov_token='UNK')\n",
    "\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "print('Found %d unique words.' % len(tokenizer.word_index))\n",
    "\n",
    "# texts_to_sequences: Transforms each text in texts to a sequence of integers. \n",
    "# It basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
    "\n",
    "train_texts_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "# pad_sequences: Ensure that all sequences in a list have the same length. \n",
    "train_texts_pad_sequences = pad_sequences(train_texts_sequences, maxlen=80, padding='post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06b41a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'joy', 'sadness', 'fear', 'love', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23e72058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "emotions = {'sadness': 0, 'joy': 1, 'surprise': 2, 'love': 3, 'anger': 4, 'fear': 5}\n",
    "\n",
    "# Step 1: Replace all emotion values with integers\n",
    "train['Emotion'] = train.Emotion.replace(emotions)\n",
    "train_emotion_integers = train['Emotion'].values\n",
    "\n",
    "# Step 2: Changing the integers to binary\n",
    "train_emotion_categorical = to_categorical(train_emotion_integers)\n",
    "\n",
    "train_emotion_categorical[:6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a68cf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_texts = validate['Text']\n",
    "validate_emotion_integers = validate.Emotion.replace(emotions)\n",
    "validate_texts_sequences = tokenizer.texts_to_sequences(validate_texts)\n",
    "validate_texts_pad_sequences = pad_sequences(validate_texts_sequences, maxlen=80, padding='post')\n",
    "validate_emotion_categorical = to_categorical(validate_emotion_integers.values)\n",
    "validate_emotion_categorical[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0f83991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "  tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "  tpu_strategy = tf.distribute.get_strategy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca6d9875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 80, 64)            973568    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 80, 64)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 80, 160)          92800     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 320)              410880    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1926      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,479,174\n",
      "Trainable params: 1,479,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,Dense,Embedding,Dropout\n",
    "\n",
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "with tpu_strategy.scope():\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(15212,64,input_length=80))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Bidirectional(LSTM(80,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(160)))\n",
    "    model.add(Dense(len(emotions),activation='softmax'))\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaff8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "242d7b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 107s 275ms/step - loss: 1.2781 - accuracy: 0.4927 - val_loss: 0.7815 - val_accuracy: 0.7312\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 96s 257ms/step - loss: 0.5575 - accuracy: 0.8074 - val_loss: 0.4238 - val_accuracy: 0.8605\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 106s 283ms/step - loss: 0.2914 - accuracy: 0.8995 - val_loss: 0.3218 - val_accuracy: 0.8895\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 97s 258ms/step - loss: 0.1944 - accuracy: 0.9333 - val_loss: 0.2975 - val_accuracy: 0.8965\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 97s 260ms/step - loss: 0.1531 - accuracy: 0.9457 - val_loss: 0.2811 - val_accuracy: 0.9013\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 95s 254ms/step - loss: 0.1224 - accuracy: 0.9585 - val_loss: 0.2725 - val_accuracy: 0.9013\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 88s 236ms/step - loss: 0.1018 - accuracy: 0.9641 - val_loss: 0.2785 - val_accuracy: 0.9038\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 102s 272ms/step - loss: 0.0871 - accuracy: 0.9669 - val_loss: 0.2946 - val_accuracy: 0.9028\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 101s 269ms/step - loss: 0.0775 - accuracy: 0.9721 - val_loss: 0.2999 - val_accuracy: 0.9035\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 98s 261ms/step - loss: 0.0745 - accuracy: 0.9736 - val_loss: 0.2908 - val_accuracy: 0.9097\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(train_texts_pad_sequences, train_emotion_categorical, epochs=10, validation_data = (validate_texts_pad_sequences, validate_emotion_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0788586c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Text'] = test['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "\n",
    "test_texts = test['Text']\n",
    "test_emotion_integers = test.Emotion.replace(emotions)\n",
    "test_texts_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_texts_pad_sequences = pad_sequences(test_texts_sequences, maxlen=80, padding='post')\n",
    "test_emotion_categorical = to_categorical(test_emotion_integers.values)\n",
    "test_emotion_categorical[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0df0d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 7s 55ms/step - loss: 0.3014 - accuracy: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3014046251773834, 0.9089999794960022]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_texts_pad_sequences, test_emotion_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecd18ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_key(value):\n",
    "    for key,val in emotions.items():\n",
    "          if (val==value):\n",
    "            return key\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    text_tokens = word_tokenize(sentence)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "    return (\" \").join(tokens_without_sw)\n",
    "        \n",
    "def predict(sentence):\n",
    "    sentence = remove_stopwords(sentence.lower())\n",
    "    print(sentence)\n",
    "    sentence_lst=[]\n",
    "    sentence_lst.append(sentence)\n",
    "    sentence_seq=tokenizer.texts_to_sequences(sentence_lst)\n",
    "    sentence_padded=pad_sequences(sentence_seq,maxlen=80,padding='post')\n",
    "    certaintyprediction = model.predict(sentence_padded)[0]\n",
    "    for key,val in emotions.items():\n",
    "          print(key + ': ' + str(round(certaintyprediction[val]*100, 2)) + ' %')\n",
    "    bestpredictionindex = np.argmax(certaintyprediction)\n",
    "    certainty = str(round(certaintyprediction[bestpredictionindex]*100, 2))\n",
    "    print('\\nI am '+ certainty + ' % sure the emotion is ' + get_key(bestpredictionindex) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baa396f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rude .\n",
      "sadness: 0.67 %\n",
      "joy: 0.05 %\n",
      "surprise: 0.36 %\n",
      "love: 0.09 %\n",
      "anger: 98.11 %\n",
      "fear: 0.72 %\n",
      "\n",
      "I am 98.11 % sure the emotion is anger.\n"
     ]
    }
   ],
   "source": [
    "predict(\"You are being very rude.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b555f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprised dog\n",
      "sadness: 1.77 %\n",
      "joy: 2.13 %\n",
      "surprise: 76.99 %\n",
      "love: 0.66 %\n",
      "anger: 10.14 %\n",
      "fear: 8.31 %\n",
      "\n",
      "I am 76.99 % sure the emotion is surprise.\n"
     ]
    }
   ],
   "source": [
    "predict(\"I surprised my dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce6b80",
   "metadata": {},
   "source": [
    "## 2. Machine learning models Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c18dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train.Text.values, train.Emotion, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50f0a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10b228fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exm = ['I am very happy today! The atmosphere looks cheerful',\n",
    "        'Things are looking great. It was such a good day',\n",
    "        'Success is right around the corner. Lets celebrate this victory',\n",
    "        'Everything is more beautiful when you experience them with a smile!',\n",
    "        'Now this is my worst, okay? But I am gonna get better.',\n",
    "        'I am tired, boss. Tired of being on the road, lonely as a sparrow in the rain. I am tired of all the pain I feel',\n",
    "        'This is quite depressing. I am filled with sorrow',\n",
    "        'His death broke my heart. It was a sad day', \n",
    "        'i hate this',\n",
    "        'I dont love you anymore..!',\n",
    "        'This looks so impressive',\n",
    "        'surprised',\n",
    "        'like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aeb2dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a280190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(train['Text'])\n",
    "X_train_count =  count_vect.transform(X_train)\n",
    "X_val_count =  count_vect.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ed87c",
   "metadata": {},
   "source": [
    "### 2.1 Logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d0a9a",
   "metadata": {},
   "source": [
    "#### 2.1.1 Logistic regression with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9108540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression tfidf accuracy 0.2991666666666667\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "y_pred = logreg.predict(X_val_tfidf)\n",
    "print('logistic regression tfidf accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507e570",
   "metadata": {},
   "source": [
    "#### 2.1.2 Logistic regression with count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99027074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression count vectors accuracy 0.8725\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(X_train_count, y_train)\n",
    "y_pred = logreg.predict(X_val_count)\n",
    "print('logistic regression count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89d417",
   "metadata": {},
   "source": [
    "### 2.2  Multinomial naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713abee",
   "metadata": {},
   "source": [
    "#### 2.2.1 Multinomial naive bayes with tfdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd01d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes tfidf accuracy 0.31333333333333335\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "y_pred = nb.predict(X_val_tfidf)\n",
    "print('naive bayes tfidf accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4abb0",
   "metadata": {},
   "source": [
    "#### 2.2.2  Multinomial naive bayes with count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa905844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes count vectors accuracy 0.7683333333333333\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_count, y_train)\n",
    "y_pred = nb.predict(X_val_count)\n",
    "print('naive bayes count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4295a",
   "metadata": {},
   "source": [
    "### 2.3 Multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72167a9",
   "metadata": {},
   "source": [
    "#### 2.3.1 Multilayer perceptron with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7355fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP tfidf accuracy 0.28\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train_tfidf, y_train)\n",
    "y_pred = mlp.predict(X_val_tfidf)\n",
    "print('MLP tfidf accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597f988",
   "metadata": {},
   "source": [
    "#### 2.3.2 Multilayer perceptron with count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8491eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP count vectors accuracy 0.8483333333333334\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train_count, y_train)\n",
    "y_pred = mlp.predict(X_val_count)\n",
    "print('MLP count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f24d8b",
   "metadata": {},
   "source": [
    "### 2.4 Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13bb8d",
   "metadata": {},
   "source": [
    "#### 2.4.1  LSVM with tfdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28b3566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvm using tfidf accuracy 0.31\n"
     ]
    }
   ],
   "source": [
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(X_train_tfidf, y_train)\n",
    "y_pred = lsvm.predict(X_val_tfidf)\n",
    "print('lsvm using tfidf accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd59660",
   "metadata": {},
   "source": [
    "#### 2.4.2  LSVM with count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a316373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvm using count vectors accuracy 0.8866666666666667\n"
     ]
    }
   ],
   "source": [
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(X_train_count, y_train)\n",
    "y_pred = lsvm.predict(X_val_count)\n",
    "print('lsvm using count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704b375",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e92aa5",
   "metadata": {},
   "source": [
    "### Model Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c81e6b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "model_json = model.to_json()\n",
    "with open(\"model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "298da070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# dump information to that file\n",
    "pickle.dump(tokenizer, open('model/tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4fec8",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d39b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from flask import Flask, request, render_template\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f70516c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(value):\n",
    "    for key,val in emotions.items():\n",
    "          if (val==value):\n",
    "            return key\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    text_tokens = word_tokenize(sentence)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "    return (\" \").join(tokens_without_sw)\n",
    "        \n",
    "def predict_deep(sentence,model):\n",
    "    sentence = remove_stopwords(sentence.lower())\n",
    "    sentence_lst=[]\n",
    "    sentence_lst.append(sentence)\n",
    "    sentence_seq=tokenizer.texts_to_sequences(sentence_lst)\n",
    "    sentence_padded=pad_sequences(sentence_seq,maxlen=80,padding='post')\n",
    "    certaintyprediction = model.predict(sentence_padded)[0]\n",
    "    rescertainity = [round(x*100) for x in certaintyprediction]\n",
    "    #print(rescertainity)\n",
    "    bestpredictionindex = np.argmax(certaintyprediction)\n",
    "    \n",
    "    certainty = str(round(certaintyprediction[bestpredictionindex]*100, 2))\n",
    "    return [rescertainity, get_key(bestpredictionindex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "155a9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {'sadness': 0, 'joy': 1, 'surprise': 2, 'love': 3, 'anger': 4, 'fear': 5}\n",
    "\n",
    "tokenizer_file = open(\"model/tokenizer.pkl\",\"rb\")\n",
    "tokenizer = pickle.load(tokenizer_file)\n",
    "tokenizer_file.close()\n",
    "\n",
    "json_file = open('model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"model/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32620b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 26, 6, 12, 42, 4]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love animals\"\n",
    "percents, mood = predict_deep(sentence,loaded_model)\n",
    "print(percents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672f6fd",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Successfully implemented emotion detection for text documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
