{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15760919",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9529b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec61c0",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c5bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\n",
    "    os.path.join(os.getcwd(),\"../static/dataset/train.txt\"),\n",
    "    sep=\";\",\n",
    "    names=[\"Text\",\"Emotion\"],\n",
    "    encoding='utf-8')\n",
    "\n",
    "validate=pd.read_csv(\n",
    "   os.path.join(os.getcwd(),\"../static/dataset/val.txt\"),\n",
    "    sep=\";\",\n",
    "    names=[\"Text\",\"Emotion\"],\n",
    "    encoding='utf-8')\n",
    "\n",
    "test=pd.read_csv( \n",
    "    os.path.join(os.getcwd(),\"../static/dataset/test.txt\"),\n",
    "    sep=\";\",\n",
    "    names=[\"Text\",\"Emotion\"],\n",
    "    encoding='utf-8')\n",
    "\n",
    "merged = pd.concat([train, validate, test], ignore_index=True)\n",
    "\n",
    "datasets = [train, validate, test]\n",
    "datasetnames = ['Train', 'Validate', 'Test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a511f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b02889",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f22779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "train['Text'] = train['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "validate['Text'] = validate['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503198ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion\n",
       "0                              didnt feel humiliated  sadness\n",
       "1  go feeling hopeless damned hopeful around some...  sadness\n",
       "2          im grabbing minute post feel greedy wrong    anger\n",
       "3  ever feeling nostalgic fireplace know still pr...     love\n",
       "4                                    feeling grouchy    anger"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81517c86",
   "metadata": {},
   "source": [
    "Converting words to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5baaa032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>brief time beanbag said anna feel like beaten</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>turning feel pathetic still waiting tables sub...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>feel strong good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>feel like rude comment im glad</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>know lot feel stupid portray</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                                  didnt feel humiliated  sadness\n",
       "1      go feeling hopeless damned hopeful around some...  sadness\n",
       "2              im grabbing minute post feel greedy wrong    anger\n",
       "3      ever feeling nostalgic fireplace know still pr...     love\n",
       "4                                        feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "15995      brief time beanbag said anna feel like beaten  sadness\n",
       "15996  turning feel pathetic still waiting tables sub...  sadness\n",
       "15997                           feel strong good overall      joy\n",
       "15998                     feel like rude comment im glad    anger\n",
       "15999                       know lot feel stupid portray  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'] = train['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ba974",
   "metadata": {},
   "source": [
    "Removing Punctuation, Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73d0fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>brief time beanbag said anna feel like beaten</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>turning feel pathetic still waiting tables sub...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>feel strong good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>feel like rude comment im glad</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>know lot feel stupid portray</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                                  didnt feel humiliated  sadness\n",
       "1      go feeling hopeless damned hopeful around some...  sadness\n",
       "2              im grabbing minute post feel greedy wrong    anger\n",
       "3      ever feeling nostalgic fireplace know still pr...     love\n",
       "4                                        feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "15995      brief time beanbag said anna feel like beaten  sadness\n",
       "15996  turning feel pathetic still waiting tables sub...  sadness\n",
       "15997                           feel strong good overall      joy\n",
       "15998                     feel like rude comment im glad    anger\n",
       "15999                       know lot feel stupid portray  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'] = train['Text'].str.replace('[^\\w\\s]',' ')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297d623e",
   "metadata": {},
   "source": [
    "Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe8a4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>brief time beanbag said anna feel like beaten</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>turning feel pathetic still waiting table subb...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>feel strong good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>feel like rude comment im glad</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>know lot feel stupid portray</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                                  didnt feel humiliated  sadness\n",
       "1      go feeling hopeless damned hopeful around some...  sadness\n",
       "2              im grabbing minute post feel greedy wrong    anger\n",
       "3      ever feeling nostalgic fireplace know still pr...     love\n",
       "4                                        feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "15995      brief time beanbag said anna feel like beaten  sadness\n",
       "15996  turning feel pathetic still waiting table subb...  sadness\n",
       "15997                           feel strong good overall      joy\n",
       "15998                     feel like rude comment im glad    anger\n",
       "15999                       know lot feel stupid portray  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'] = train['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466d3be",
   "metadata": {},
   "source": [
    "Correcting Letter Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6e75e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>brief time beanbag said anna feel like beaten</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>turning feel pathetic still waiting table subb...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>feel strong good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>feel like rude comment im glad</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>know lot feel stupid portray</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                                  didnt feel humiliated  sadness\n",
       "1      go feeling hopeless damned hopeful around some...  sadness\n",
       "2              im grabbing minute post feel greedy wrong    anger\n",
       "3      ever feeling nostalgic fireplace know still pr...     love\n",
       "4                                        feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "15995      brief time beanbag said anna feel like beaten  sadness\n",
       "15996  turning feel pathetic still waiting table subb...  sadness\n",
       "15997                           feel strong good overall      joy\n",
       "15998                     feel like rude comment im glad    anger\n",
       "15999                       know lot feel stupid portray  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "train['Text'] = train['Text'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564dccc",
   "metadata": {},
   "source": [
    "## 1. Deep learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6202e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13454 unique words.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_texts = train['Text']\n",
    "\n",
    "tokenizer = Tokenizer(15212,lower=True,oov_token='UNK')\n",
    "\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "print('Found %d unique words.' % len(tokenizer.word_index))\n",
    "\n",
    "# texts_to_sequences: Transforms each text in texts to a sequence of integers. \n",
    "# It basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
    "\n",
    "train_texts_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "# pad_sequences: Ensure that all sequences in a list have the same length. \n",
    "train_texts_pad_sequences = pad_sequences(train_texts_sequences, maxlen=80, padding='post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b41a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'anger', 'love', 'surprise', 'fear', 'joy'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23e72058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "emotions = {'sadness': 0, 'joy': 1, 'surprise': 2, 'love': 3, 'anger': 4, 'fear': 5}\n",
    "\n",
    "# Step 1: Replace all emotion values with integers\n",
    "train['Emotion'] = train.Emotion.replace(emotions)\n",
    "train_emotion_integers = train['Emotion'].values\n",
    "\n",
    "# Step 2: Changing the integers to binary\n",
    "train_emotion_categorical = to_categorical(train_emotion_integers)\n",
    "\n",
    "train_emotion_categorical[:6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a68cf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_texts = validate['Text']\n",
    "validate_emotion_integers = validate.Emotion.replace(emotions)\n",
    "validate_texts_sequences = tokenizer.texts_to_sequences(validate_texts)\n",
    "validate_texts_pad_sequences = pad_sequences(validate_texts_sequences, maxlen=80, padding='post')\n",
    "validate_emotion_categorical = to_categorical(validate_emotion_integers.values)\n",
    "validate_emotion_categorical[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0f83991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "  tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "  tpu_strategy = tf.distribute.get_strategy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca6d9875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 80, 64)            973568    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 80, 64)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 80, 160)          92800     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 320)              410880    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1926      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,479,174\n",
      "Trainable params: 1,479,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional,Dense,Embedding,Dropout\n",
    "\n",
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "with tpu_strategy.scope():\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(15212,64,input_length=80))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Bidirectional(LSTM(80,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(160)))\n",
    "    model.add(Dense(len(emotions),activation='softmax'))\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaff8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "242d7b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 251s 477ms/step - loss: 1.0888 - accuracy: 0.5826 - val_loss: 0.4548 - val_accuracy: 0.8510\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 225s 451ms/step - loss: 0.3597 - accuracy: 0.8770 - val_loss: 0.2470 - val_accuracy: 0.9115\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 228s 457ms/step - loss: 0.2088 - accuracy: 0.9262 - val_loss: 0.2129 - val_accuracy: 0.9170\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 232s 465ms/step - loss: 0.1524 - accuracy: 0.9448 - val_loss: 0.2073 - val_accuracy: 0.9185\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 212s 423ms/step - loss: 0.1238 - accuracy: 0.9528 - val_loss: 0.1992 - val_accuracy: 0.9180\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 204s 408ms/step - loss: 0.1064 - accuracy: 0.9575 - val_loss: 0.1967 - val_accuracy: 0.9220\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 205s 410ms/step - loss: 0.0924 - accuracy: 0.9659 - val_loss: 0.1976 - val_accuracy: 0.9240\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 238s 476ms/step - loss: 0.0804 - accuracy: 0.9686 - val_loss: 0.1999 - val_accuracy: 0.9240\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 246s 492ms/step - loss: 0.0658 - accuracy: 0.9737 - val_loss: 0.2150 - val_accuracy: 0.9295\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 240s 480ms/step - loss: 0.0632 - accuracy: 0.9754 - val_loss: 0.2435 - val_accuracy: 0.9265\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(train_texts_pad_sequences, train_emotion_categorical, epochs=10, validation_data = (validate_texts_pad_sequences, validate_emotion_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0788586c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Text'] = test['Text'].apply(lambda x: ' '.join([item for item in str(x).split() if item not in stopwords.words('english')]))\n",
    "\n",
    "test_texts = test['Text']\n",
    "test_emotion_integers = test.Emotion.replace(emotions)\n",
    "test_texts_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_texts_pad_sequences = pad_sequences(test_texts_sequences, maxlen=80, padding='post')\n",
    "test_emotion_categorical = to_categorical(test_emotion_integers.values)\n",
    "test_emotion_categorical[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0df0d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 8s 126ms/step - loss: 0.2480 - accuracy: 0.9195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24799197912216187, 0.9194999933242798]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_texts_pad_sequences, test_emotion_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecd18ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_key(value):\n",
    "    for key,val in emotions.items():\n",
    "          if (val==value):\n",
    "            return key\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    text_tokens = word_tokenize(sentence)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "    return (\" \").join(tokens_without_sw)\n",
    "        \n",
    "def predict(sentence):\n",
    "    sentence = remove_stopwords(sentence.lower())\n",
    "    print(sentence)\n",
    "    sentence_lst=[]\n",
    "    sentence_lst.append(sentence)\n",
    "    sentence_seq=tokenizer.texts_to_sequences(sentence_lst)\n",
    "    sentence_padded=pad_sequences(sentence_seq,maxlen=80,padding='post')\n",
    "    certaintyprediction = model.predict(sentence_padded)[0]\n",
    "    for key,val in emotions.items():\n",
    "          print(key + ': ' + str(round(certaintyprediction[val]*100, 2)) + ' %')\n",
    "    bestpredictionindex = np.argmax(certaintyprediction)\n",
    "    certainty = str(round(certaintyprediction[bestpredictionindex]*100, 2))\n",
    "    print('\\nI am '+ certainty + ' % sure the emotion is ' + get_key(bestpredictionindex) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baa396f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rude .\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "sadness: 0.37 %\n",
      "joy: 0.03 %\n",
      "surprise: 0.02 %\n",
      "love: 0.05 %\n",
      "anger: 99.44 %\n",
      "fear: 0.09 %\n",
      "\n",
      "I am 99.44 % sure the emotion is anger.\n"
     ]
    }
   ],
   "source": [
    "predict(\"You are being very rude.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b555f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprised dog\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "sadness: 6.32 %\n",
      "joy: 6.01 %\n",
      "surprise: 60.18 %\n",
      "love: 3.81 %\n",
      "anger: 2.04 %\n",
      "fear: 21.64 %\n",
      "\n",
      "I am 60.18 % sure the emotion is surprise.\n"
     ]
    }
   ],
   "source": [
    "predict(\"I surprised my dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce6b80",
   "metadata": {},
   "source": [
    "## 2. Machine learning models Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c18dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train.Text.values, train.Emotion, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50f0a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10b228fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exm = ['I am very happy today! The atmosphere looks cheerful',\n",
    "        'Things are looking great. It was such a good day',\n",
    "        'Success is right around the corner. Lets celebrate this victory',\n",
    "        'Everything is more beautiful when you experience them with a smile!',\n",
    "        'Now this is my worst, okay? But I am gonna get better.',\n",
    "        'I am tired, boss. Tired of being on the road, lonely as a sparrow in the rain. I am tired of all the pain I feel',\n",
    "        'This is quite depressing. I am filled with sorrow',\n",
    "        'His death broke my heart. It was a sad day', \n",
    "        'i hate this',\n",
    "        'I dont love you anymore..!',\n",
    "        'This looks so impressive',\n",
    "        'surprised',\n",
    "        'like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeb2dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a280190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(train['Text'])\n",
    "X_train_count =  count_vect.transform(X_train)\n",
    "X_val_count =  count_vect.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ed87c",
   "metadata": {},
   "source": [
    "### 2.1 Logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d0a9a",
   "metadata": {},
   "source": [
    "#### 2.1.1 Logistic regression with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9108540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression tfidf accuracy 0.283125\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "y_pred = logreg.predict(X_val_tfidf)\n",
    "print('logistic regression tfidf accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507e570",
   "metadata": {},
   "source": [
    "#### 2.1.2 Logistic regression with count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99027074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression count vectors accuracy 0.90375\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(X_train_count, y_train)\n",
    "y_pred = logreg.predict(X_val_count)\n",
    "print('logistic regression count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89d417",
   "metadata": {},
   "source": [
    "### 2.2  Multinomial naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713abee",
   "metadata": {},
   "source": [
    "#### 2.2.1 Multinomial naive bayes with tfdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd01d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes tfidf accuracy 0.289375\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "y_pred = nb.predict(X_val_tfidf)\n",
    "print('naive bayes tfidf accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4abb0",
   "metadata": {},
   "source": [
    "#### 2.2.2  Multinomial naive bayes with count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa905844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes count vectors accuracy 0.795625\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_count, y_train)\n",
    "y_pred = nb.predict(X_val_count)\n",
    "print('naive bayes count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4295a",
   "metadata": {},
   "source": [
    "### 2.3 Multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72167a9",
   "metadata": {},
   "source": [
    "#### 2.3.1 Multilayer perceptron with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7355fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP tfidf accuracy 0.265\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train_tfidf, y_train)\n",
    "y_pred = mlp.predict(X_val_tfidf)\n",
    "print('MLP tfidf accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597f988",
   "metadata": {},
   "source": [
    "#### 2.3.2 Multilayer perceptron with count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8491eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP count vectors accuracy 0.864375\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train_count, y_train)\n",
    "y_pred = mlp.predict(X_val_count)\n",
    "print('MLP count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f24d8b",
   "metadata": {},
   "source": [
    "### 2.4 Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13bb8d",
   "metadata": {},
   "source": [
    "#### 2.4.1  LSVM with tfdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28b3566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvm using tfidf accuracy 0.28375\n"
     ]
    }
   ],
   "source": [
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(X_train_tfidf, y_train)\n",
    "y_pred = lsvm.predict(X_val_tfidf)\n",
    "print('lsvm using tfidf accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd59660",
   "metadata": {},
   "source": [
    "#### 2.4.2  LSVM with count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a316373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvm using count vectors accuracy 0.90125\n"
     ]
    }
   ],
   "source": [
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(X_train_count, y_train)\n",
    "y_pred = lsvm.predict(X_val_count)\n",
    "print('lsvm using count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704b375",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e92aa5",
   "metadata": {},
   "source": [
    "### Model Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c81e6b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "model_json = model.to_json()\n",
    "with open(\"../static/model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"../static/model/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "298da070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# dump information to that file\n",
    "pickle.dump(tokenizer, open('../static/model/tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4fec8",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d39b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from flask import Flask, request, render_template\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f70516c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(value):\n",
    "    for key,val in emotions.items():\n",
    "          if (val==value):\n",
    "            return key\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    text_tokens = word_tokenize(sentence)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "    return (\" \").join(tokens_without_sw)\n",
    "        \n",
    "def predict_deep(sentence,model):\n",
    "    sentence = remove_stopwords(sentence.lower())\n",
    "    sentence_lst=[]\n",
    "    sentence_lst.append(sentence)\n",
    "    sentence_seq=tokenizer.texts_to_sequences(sentence_lst)\n",
    "    sentence_padded=pad_sequences(sentence_seq,maxlen=80,padding='post')\n",
    "    certaintyprediction = model.predict(sentence_padded)[0]\n",
    "    rescertainity = [round(x*100) for x in certaintyprediction]\n",
    "    #print(rescertainity)\n",
    "    bestpredictionindex = np.argmax(certaintyprediction)\n",
    "    \n",
    "    certainty = str(round(certaintyprediction[bestpredictionindex]*100, 2))\n",
    "    return [rescertainity, get_key(bestpredictionindex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "155a9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {'sadness': 0, 'joy': 1, 'surprise': 2, 'love': 3, 'anger': 4, 'fear': 5}\n",
    "\n",
    "tokenizer_file = open(\"../static/model/tokenizer.pkl\",\"rb\")\n",
    "tokenizer = pickle.load(tokenizer_file)\n",
    "tokenizer_file.close()\n",
    "\n",
    "json_file = open('../static/model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"../static/model/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32620b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "[11, 25, 9, 12, 15, 28]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love animals\"\n",
    "percents, mood = predict_deep(sentence,loaded_model)\n",
    "print(percents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672f6fd",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Successfully implemented emotion detection for text documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
